{
  "RasaHQ/financial-demo": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7333333333333333,
          "precision": 0.8,
          "recall": 0.7,
          "support": 14
        },
        "micro avg": {
          "f1-score": 0.8333333333333333,
          "precision": 1.0,
          "recall": 0.7142857142857143,
          "support": 14
        },
        "weighted avg": {
          "f1-score": 0.738095238095238,
          "precision": 0.7857142857142857,
          "recall": 0.7142857142857143,
          "support": 14
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        }
      },
      "test_run_time": "35s",
      "total_run_time": "2m2s",
      "train_run_time": "1m28s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7333333333333333,
          "precision": 0.8,
          "recall": 0.7,
          "support": 14
        },
        "micro avg": {
          "f1-score": 0.8333333333333333,
          "precision": 1.0,
          "recall": 0.7142857142857143,
          "support": 14
        },
        "weighted avg": {
          "f1-score": 0.738095238095238,
          "precision": 0.7857142857142857,
          "recall": 0.7142857142857143,
          "support": 14
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        }
      },
      "test_run_time": "55s",
      "total_run_time": "2m8s",
      "train_run_time": "1m14s",
      "type": "nlu"
    },
    "Rules": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.5416666666666666,
          "correct": 26,
          "total": 48,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.627314732492726,
          "precision": 0.7142857142857143,
          "recall": 0.5787829563064614,
          "support": 317
        },
        "micro avg": {
          "f1-score": 0.7217741935483871,
          "precision": 1.0,
          "recall": 0.5646687697160884,
          "support": 317
        },
        "weighted avg": {
          "f1-score": 0.6593956407315875,
          "precision": 0.8107255520504731,
          "recall": 0.5646687697160884,
          "support": 317
        }
      },
      "test_run_time": "13s",
      "total_run_time": "32s",
      "train_run_time": "20s",
      "type": "core"
    },
    "Rules + AugMemo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 48,
          "total": 48,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 317
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 317
        }
      },
      "test_run_time": "13s",
      "total_run_time": "34s",
      "train_run_time": "22s",
      "type": "core"
    },
    "Rules + AugMemo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 48,
          "total": 48,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 317
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 317
        }
      },
      "test_run_time": "52s",
      "total_run_time": "8m19s",
      "train_run_time": "7m28s",
      "type": "core"
    },
    "Rules + Memo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.9166666666666666,
          "correct": 44,
          "total": 48,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.9512003148366784,
          "precision": 0.9523809523809523,
          "recall": 0.9500768049155146,
          "support": 317
        },
        "micro avg": {
          "f1-score": 0.9807073954983923,
          "precision": 1.0,
          "recall": 0.9621451104100947,
          "support": 317
        },
        "weighted avg": {
          "f1-score": 0.971374195062179,
          "precision": 0.9810725552050473,
          "recall": 0.9621451104100947,
          "support": 317
        }
      },
      "test_run_time": "12s",
      "total_run_time": "34s",
      "train_run_time": "23s",
      "type": "core"
    },
    "Rules + Memo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 48,
          "total": 48,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 317
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 317
        }
      },
      "test_run_time": "51s",
      "total_run_time": "8m15s",
      "train_run_time": "7m24s",
      "type": "core"
    },
    "Rules + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.6875,
          "correct": 33,
          "total": 48,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.8570414974635754,
          "precision": 0.8957671957671958,
          "recall": 0.8501256756239565,
          "support": 317
        },
        "micro avg": {
          "f1-score": 0.8856209150326797,
          "precision": 0.9186440677966101,
          "recall": 0.8548895899053628,
          "support": 317
        },
        "weighted avg": {
          "f1-score": 0.8878104795978327,
          "precision": 0.9452506133894146,
          "recall": 0.8548895899053628,
          "support": 317
        }
      },
      "test_run_time": "52s",
      "total_run_time": "8m27s",
      "train_run_time": "7m36s",
      "type": "core"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7333333333333333,
          "precision": 0.8,
          "recall": 0.7,
          "support": 14
        },
        "micro avg": {
          "f1-score": 0.8333333333333333,
          "precision": 1.0,
          "recall": 0.7142857142857143,
          "support": 14
        },
        "weighted avg": {
          "f1-score": 0.7380952380952381,
          "precision": 0.7857142857142857,
          "recall": 0.7142857142857143,
          "support": 14
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        }
      },
      "test_run_time": "32s",
      "total_run_time": "1m44s",
      "train_run_time": "1m13s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.8,
          "precision": 0.8,
          "recall": 0.8,
          "support": 14
        },
        "micro avg": {
          "f1-score": 0.88,
          "precision": 1.0,
          "recall": 0.7857142857142857,
          "support": 14
        },
        "weighted avg": {
          "f1-score": 0.7857142857142857,
          "precision": 0.7857142857142857,
          "recall": 0.7857142857142857,
          "support": 14
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 28
        }
      },
      "test_run_time": "56s",
      "total_run_time": "2m15s",
      "train_run_time": "1m19s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7333333333333333,
          "precision": 0.8,
          "recall": 0.7,
          "support": 14
        },
        "micro avg": {
          "f1-score": 0.8333333333333333,
          "precision": 1.0,
          "recall": 0.7142857142857143,
          "support": 14
        },
        "weighted avg": {
          "f1-score": 0.738095238095238,
          "precision": 0.7857142857142857,
          "recall": 0.7142857142857143,
          "support": 14
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 0.9642857142857143,
        "macro avg": {
          "f1-score": 0.9644444444444444,
          "precision": 0.9777777777777777,
          "recall": 0.9666666666666667,
          "support": 28
        },
        "weighted avg": {
          "f1-score": 0.9619047619047619,
          "precision": 0.9761904761904762,
          "recall": 0.9642857142857143,
          "support": 28
        }
      },
      "test_run_time": "20s",
      "total_run_time": "1m5s",
      "train_run_time": "45s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "52a3ad3eb5292d56542687e23b06703431f15ead",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.8,
          "precision": 0.8,
          "recall": 0.8,
          "support": 14
        },
        "micro avg": {
          "f1-score": 0.88,
          "precision": 1.0,
          "recall": 0.7857142857142857,
          "support": 14
        },
        "weighted avg": {
          "f1-score": 0.7857142857142857,
          "precision": 0.7857142857142857,
          "recall": 0.7857142857142857,
          "support": 14
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 0.9642857142857143,
        "macro avg": {
          "f1-score": 0.9644444444444444,
          "precision": 0.9777777777777777,
          "recall": 0.9666666666666667,
          "support": 28
        },
        "weighted avg": {
          "f1-score": 0.9619047619047619,
          "precision": 0.9761904761904762,
          "recall": 0.9642857142857143,
          "support": 28
        }
      },
      "test_run_time": "48s",
      "total_run_time": "1m55s",
      "train_run_time": "1m7s",
      "type": "nlu"
    }
  },
  "RasaHQ/helpdesk-assistant": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        }
      },
      "test_run_time": "29s",
      "total_run_time": "1m52s",
      "train_run_time": "1m24s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        }
      },
      "test_run_time": "48s",
      "total_run_time": "1m59s",
      "train_run_time": "1m11s",
      "type": "nlu"
    },
    "Rules": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.25,
          "correct": 3,
          "total": 12,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.4320987654320988,
          "precision": 0.4666666666666667,
          "recall": 0.4147368421052632,
          "support": 50
        },
        "micro avg": {
          "f1-score": 0.5714285714285715,
          "precision": 1.0,
          "recall": 0.4,
          "support": 50
        },
        "weighted avg": {
          "f1-score": 0.47407407407407404,
          "precision": 0.64,
          "recall": 0.4,
          "support": 50
        }
      },
      "test_run_time": "9s",
      "total_run_time": "20s",
      "train_run_time": "11s",
      "type": "core"
    },
    "Rules + AugMemo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 12,
          "total": 12,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        }
      },
      "test_run_time": "9s",
      "total_run_time": "20s",
      "train_run_time": "11s",
      "type": "core"
    },
    "Rules + AugMemo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 12,
          "total": 12,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        }
      },
      "test_run_time": "27s",
      "total_run_time": "6m28s",
      "train_run_time": "6m2s",
      "type": "core"
    },
    "Rules + Memo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.9166666666666666,
          "correct": 11,
          "total": 12,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.9315315315315315,
          "precision": 0.9333333333333333,
          "recall": 0.9298245614035088,
          "support": 50
        },
        "micro avg": {
          "f1-score": 0.9795918367346939,
          "precision": 1.0,
          "recall": 0.96,
          "support": 50
        },
        "weighted avg": {
          "f1-score": 0.9697297297297297,
          "precision": 0.98,
          "recall": 0.96,
          "support": 50
        }
      },
      "test_run_time": "10s",
      "total_run_time": "21s",
      "train_run_time": "12s",
      "type": "core"
    },
    "Rules + Memo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 12,
          "total": 12,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        }
      },
      "test_run_time": "28s",
      "total_run_time": "7m4s",
      "train_run_time": "6m37s",
      "type": "core"
    },
    "Rules + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 12,
          "total": 12,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 50
        }
      },
      "test_run_time": "26s",
      "total_run_time": "6m22s",
      "train_run_time": "5m56s",
      "type": "core"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        }
      },
      "test_run_time": "24s",
      "total_run_time": "1m21s",
      "train_run_time": "57s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        }
      },
      "test_run_time": "48s",
      "total_run_time": "1m59s",
      "train_run_time": "1m11s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        }
      },
      "test_run_time": "16s",
      "total_run_time": "57s",
      "train_run_time": "41s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "d83f20e76447faf3c6eb31f6a1bc0576f28408e1",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 13
        }
      },
      "test_run_time": "47s",
      "total_run_time": "1m55s",
      "train_run_time": "1m9s",
      "type": "nlu"
    }
  },
  "RasaHQ/insurance-demo": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "micro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        }
      },
      "test_run_time": "24s",
      "total_run_time": "1m5s",
      "train_run_time": "42s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        }
      },
      "test_run_time": "49s",
      "total_run_time": "1m50s",
      "train_run_time": "1m2s",
      "type": "nlu"
    },
    "Rules": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.0,
          "correct": 0,
          "total": 6,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.2259373998504433,
          "precision": 0.2727272727272727,
          "recall": 0.19859307359307357,
          "support": 62
        },
        "micro avg": {
          "f1-score": 0.5909090909090909,
          "precision": 1.0,
          "recall": 0.41935483870967744,
          "support": 62
        },
        "weighted avg": {
          "f1-score": 0.5132481710321822,
          "precision": 0.6774193548387096,
          "recall": 0.41935483870967744,
          "support": 62
        }
      },
      "test_run_time": "10s",
      "total_run_time": "23s",
      "train_run_time": "14s",
      "type": "core"
    },
    "Rules + AugMemo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 6,
          "total": 6,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        }
      },
      "test_run_time": "9s",
      "total_run_time": "23s",
      "train_run_time": "14s",
      "type": "core"
    },
    "Rules + AugMemo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 6,
          "total": 6,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        }
      },
      "test_run_time": "31s",
      "total_run_time": "14m19s",
      "train_run_time": "13m48s",
      "type": "core"
    },
    "Rules + Memo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.5,
          "correct": 3,
          "total": 6,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.531948051948052,
          "precision": 0.6363636363636364,
          "recall": 0.48008658008658006,
          "support": 62
        },
        "micro avg": {
          "f1-score": 0.76,
          "precision": 1.0,
          "recall": 0.6129032258064516,
          "support": 62
        },
        "weighted avg": {
          "f1-score": 0.7189861751152075,
          "precision": 0.9032258064516129,
          "recall": 0.6129032258064516,
          "support": 62
        }
      },
      "test_run_time": "9s",
      "total_run_time": "24s",
      "train_run_time": "15s",
      "type": "core"
    },
    "Rules + Memo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 6,
          "total": 6,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        }
      },
      "test_run_time": "29s",
      "total_run_time": "13m37s",
      "train_run_time": "13m8s",
      "type": "core"
    },
    "Rules + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 6,
          "total": 6,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 62
        }
      },
      "test_run_time": "30s",
      "total_run_time": "13m56s",
      "train_run_time": "13m27s",
      "type": "core"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "micro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        }
      },
      "test_run_time": "23s",
      "total_run_time": "1m9s",
      "train_run_time": "47s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "micro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        }
      },
      "test_run_time": "50s",
      "total_run_time": "1m55s",
      "train_run_time": "1m6s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "micro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        }
      },
      "test_run_time": "17s",
      "total_run_time": "53s",
      "train_run_time": "36s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "71b6ac6f9854f63e1c30b9c1ec744c9d9abf5a1a",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "micro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 1
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 3
        }
      },
      "test_run_time": "47s",
      "total_run_time": "1m45s",
      "train_run_time": "59s",
      "type": "nlu"
    }
  },
  "RasaHQ/retail-demo": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.25,
          "precision": 0.25,
          "recall": 0.25,
          "support": 6
        },
        "micro avg": {
          "f1-score": 0.2857142857142857,
          "precision": 1.0,
          "recall": 0.16666666666666666,
          "support": 6
        },
        "weighted avg": {
          "f1-score": 0.16666666666666666,
          "precision": 0.16666666666666666,
          "recall": 0.16666666666666666,
          "support": 6
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.8,
          "precision": 0.8,
          "recall": 0.85,
          "support": 16
        },
        "micro avg": {
          "f1-score": 0.8387096774193549,
          "precision": 0.8666666666666667,
          "recall": 0.8125,
          "support": 16
        },
        "weighted avg": {
          "f1-score": 0.8125,
          "precision": 0.875,
          "recall": 0.8125,
          "support": 16
        }
      },
      "test_run_time": "29s",
      "total_run_time": "1m16s",
      "train_run_time": "47s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.25,
          "precision": 0.25,
          "recall": 0.25,
          "support": 6
        },
        "micro avg": {
          "f1-score": 0.2857142857142857,
          "precision": 1.0,
          "recall": 0.16666666666666666,
          "support": 6
        },
        "weighted avg": {
          "f1-score": 0.16666666666666666,
          "precision": 0.16666666666666666,
          "recall": 0.16666666666666666,
          "support": 6
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 0.875,
        "macro avg": {
          "f1-score": 0.8300000000000001,
          "precision": 0.8166666666666667,
          "recall": 0.85,
          "support": 16
        },
        "weighted avg": {
          "f1-score": 0.85,
          "precision": 0.8333333333333333,
          "recall": 0.875,
          "support": 16
        }
      },
      "test_run_time": "56s",
      "total_run_time": "2m2s",
      "train_run_time": "1m6s",
      "type": "nlu"
    },
    "Rules": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.7777777777777778,
          "correct": 7,
          "total": 9,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.9482804232804233,
          "precision": 1.0,
          "recall": 0.9248436748436748,
          "support": 67
        },
        "micro avg": {
          "f1-score": 0.953125,
          "precision": 1.0,
          "recall": 0.9104477611940298,
          "support": 67
        },
        "weighted avg": {
          "f1-score": 0.9441719971570718,
          "precision": 1.0,
          "recall": 0.9104477611940298,
          "support": 67
        }
      },
      "test_run_time": "10s",
      "total_run_time": "19s",
      "train_run_time": "9s",
      "type": "core"
    },
    "Rules + AugMemo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.8888888888888888,
          "correct": 8,
          "total": 9,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.9663698541747322,
          "precision": 1.0,
          "recall": 0.946007696007696,
          "support": 67
        },
        "micro avg": {
          "f1-score": 0.9692307692307692,
          "precision": 1.0,
          "recall": 0.9402985074626866,
          "support": 67
        },
        "weighted avg": {
          "f1-score": 0.9656317714563074,
          "precision": 1.0,
          "recall": 0.9402985074626866,
          "support": 67
        }
      },
      "test_run_time": "10s",
      "total_run_time": "19s",
      "train_run_time": "9s",
      "type": "core"
    },
    "Rules + AugMemo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 9,
          "total": 9,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 67
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 67
        }
      },
      "test_run_time": "28s",
      "total_run_time": "4m30s",
      "train_run_time": "4m2s",
      "type": "core"
    },
    "Rules + Memo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.8888888888888888,
          "correct": 8,
          "total": 9,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.9663698541747322,
          "precision": 1.0,
          "recall": 0.946007696007696,
          "support": 67
        },
        "micro avg": {
          "f1-score": 0.9692307692307692,
          "precision": 1.0,
          "recall": 0.9402985074626866,
          "support": 67
        },
        "weighted avg": {
          "f1-score": 0.9656317714563074,
          "precision": 1.0,
          "recall": 0.9402985074626866,
          "support": 67
        }
      },
      "test_run_time": "10s",
      "total_run_time": "19s",
      "train_run_time": "10s",
      "type": "core"
    },
    "Rules + Memo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 9,
          "total": 9,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 67
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 67
        }
      },
      "test_run_time": "31s",
      "total_run_time": "4m57s",
      "train_run_time": "4m27s",
      "type": "core"
    },
    "Rules + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "external_dataset_repository": true,
      "story_prediction": {
        "accuracy": 1.0,
        "conversation_accuracy": {
          "accuracy": 1.0,
          "correct": 9,
          "total": 9,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 67
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 67
        }
      },
      "test_run_time": "27s",
      "total_run_time": "4m29s",
      "train_run_time": "4m2s",
      "type": "core"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.25,
          "precision": 0.25,
          "recall": 0.25,
          "support": 6
        },
        "micro avg": {
          "f1-score": 0.2857142857142857,
          "precision": 1.0,
          "recall": 0.16666666666666666,
          "support": 6
        },
        "weighted avg": {
          "f1-score": 0.16666666666666666,
          "precision": 0.16666666666666666,
          "recall": 0.16666666666666666,
          "support": 6
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 0.9375,
        "macro avg": {
          "f1-score": 0.9523809523809523,
          "precision": 0.95,
          "recall": 0.975,
          "support": 16
        },
        "weighted avg": {
          "f1-score": 0.9434523809523809,
          "precision": 0.96875,
          "recall": 0.9375,
          "support": 16
        }
      },
      "test_run_time": "29s",
      "total_run_time": "1m22s",
      "train_run_time": "53s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.25,
          "precision": 0.25,
          "recall": 0.25,
          "support": 6
        },
        "micro avg": {
          "f1-score": 0.2857142857142857,
          "precision": 1.0,
          "recall": 0.16666666666666666,
          "support": 6
        },
        "weighted avg": {
          "f1-score": 0.16666666666666666,
          "precision": 0.16666666666666666,
          "recall": 0.16666666666666666,
          "support": 6
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 0.8125,
        "macro avg": {
          "f1-score": 0.699047619047619,
          "precision": 0.6666666666666666,
          "recall": 0.775,
          "support": 16
        },
        "weighted avg": {
          "f1-score": 0.7726190476190476,
          "precision": 0.7708333333333333,
          "recall": 0.8125,
          "support": 16
        }
      },
      "test_run_time": "57s",
      "total_run_time": "2m6s",
      "train_run_time": "1m9s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.25,
          "precision": 0.25,
          "recall": 0.25,
          "support": 6
        },
        "micro avg": {
          "f1-score": 0.2857142857142857,
          "precision": 1.0,
          "recall": 0.16666666666666666,
          "support": 6
        },
        "weighted avg": {
          "f1-score": 0.16666666666666666,
          "precision": 0.16666666666666666,
          "recall": 0.16666666666666666,
          "support": 6
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 1.0,
        "macro avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 16
        },
        "weighted avg": {
          "f1-score": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "support": 16
        }
      },
      "test_run_time": "24s",
      "total_run_time": "1m14s",
      "train_run_time": "50s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "8226b51b4312aa4d3723098cf6d4028feea040b4",
      "dataset_repository_branch": "fix-model-regression-tests",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.25,
          "precision": 0.25,
          "recall": 0.25,
          "support": 6
        },
        "micro avg": {
          "f1-score": 0.2857142857142857,
          "precision": 1.0,
          "recall": 0.16666666666666666,
          "support": 6
        },
        "weighted avg": {
          "f1-score": 0.16666666666666666,
          "precision": 0.16666666666666666,
          "recall": 0.16666666666666666,
          "support": 6
        }
      },
      "external_dataset_repository": true,
      "intent_classification": {
        "accuracy": 0.9375,
        "macro avg": {
          "f1-score": 0.8666666666666666,
          "precision": 0.85,
          "recall": 0.9,
          "support": 16
        },
        "weighted avg": {
          "f1-score": 0.9166666666666666,
          "precision": 0.90625,
          "recall": 0.9375,
          "support": 16
        }
      },
      "test_run_time": "53s",
      "total_run_time": "1m58s",
      "train_run_time": "1m5s",
      "type": "nlu"
    }
  },
  "private/Ergo": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8744635193133047,
        "macro avg": {
          "f1-score": 0.7694559044868757,
          "precision": 0.8002691113017368,
          "recall": 0.754739588191199,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.8722277655337519,
          "precision": 0.8754583587722711,
          "recall": 0.8744635193133047,
          "support": 932
        }
      },
      "test_run_time": "2m26s",
      "total_run_time": "13m33s",
      "train_run_time": "11m7s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8830472103004292,
        "macro avg": {
          "f1-score": 0.7931350035661837,
          "precision": 0.8100025779275377,
          "recall": 0.7908064359124533,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.879482020275349,
          "precision": 0.8804866013282556,
          "recall": 0.8830472103004292,
          "support": 932
        }
      },
      "test_run_time": "3m0s",
      "total_run_time": "9m22s",
      "train_run_time": "6m22s",
      "type": "nlu"
    },
    "Spacy + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7253218884120172,
        "macro avg": {
          "f1-score": 0.5301160933054597,
          "precision": 0.5660037483115969,
          "recall": 0.5112103346350401,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.7155991511362231,
          "precision": 0.7191283368100706,
          "recall": 0.7253218884120172,
          "support": 932
        }
      },
      "test_run_time": "1m4s",
      "total_run_time": "7m39s",
      "train_run_time": "6m35s",
      "type": "nlu"
    },
    "Spacy + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7832618025751072,
        "macro avg": {
          "f1-score": 0.6086589425272957,
          "precision": 0.6213365792292538,
          "recall": 0.6087016116408245,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.7743789055884648,
          "precision": 0.7751063419589892,
          "recall": 0.7832618025751072,
          "support": 932
        }
      },
      "test_run_time": "1m37s",
      "total_run_time": "7m50s",
      "train_run_time": "6m14s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8412017167381974,
        "macro avg": {
          "f1-score": 0.740709391912089,
          "precision": 0.7822930206634157,
          "recall": 0.725675260436011,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.8381939745191351,
          "precision": 0.8432199591329844,
          "recall": 0.8412017167381974,
          "support": 932
        }
      },
      "test_run_time": "54s",
      "total_run_time": "6m28s",
      "train_run_time": "5m35s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8530042918454935,
        "macro avg": {
          "f1-score": 0.7537287620269622,
          "precision": 0.7803943719547898,
          "recall": 0.7482158083901322,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.8483070625097182,
          "precision": 0.8510660515150984,
          "recall": 0.8530042918454935,
          "support": 932
        }
      },
      "test_run_time": "1m24s",
      "total_run_time": "7m6s",
      "train_run_time": "5m43s",
      "type": "nlu"
    },
    "Sparse + Spacy + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8669527896995708,
        "macro avg": {
          "f1-score": 0.7839234894856336,
          "precision": 0.8111667097078671,
          "recall": 0.7710902212425442,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.8630364220795078,
          "precision": 0.8657437416632905,
          "recall": 0.8669527896995708,
          "support": 932
        }
      },
      "test_run_time": "1m4s",
      "total_run_time": "9m31s",
      "train_run_time": "8m28s",
      "type": "nlu"
    },
    "Sparse + Spacy + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8508583690987125,
        "macro avg": {
          "f1-score": 0.7379457243698558,
          "precision": 0.7539240308168287,
          "recall": 0.7344108538325477,
          "support": 932
        },
        "weighted avg": {
          "f1-score": 0.8470243424853294,
          "precision": 0.8479876043536478,
          "recall": 0.8508583690987125,
          "support": 932
        }
      },
      "test_run_time": "1m41s",
      "total_run_time": "9m28s",
      "train_run_time": "7m48s",
      "type": "nlu"
    }
  },
  "private/UBS/": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.9612263300270515,
          "precision": 0.9517857142857142,
          "recall": 0.970856102003643,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.9612263300270515,
          "precision": 0.9517857142857142,
          "recall": 0.970856102003643,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9612263300270515,
          "precision": 0.9517857142857143,
          "recall": 0.970856102003643,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.9095634095634095,
        "macro avg": {
          "f1-score": 0.792708922902945,
          "precision": 0.8285521671071543,
          "recall": 0.7663856727181688,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.9062924524090779,
          "precision": 0.9049306194550543,
          "recall": 0.9095634095634095,
          "support": 962
        }
      },
      "test_run_time": "2m28s",
      "total_run_time": "6m35s",
      "train_run_time": "4m8s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.9717411121239745,
          "precision": 0.9726277372262774,
          "recall": 0.970856102003643,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.9717411121239745,
          "precision": 0.9726277372262774,
          "recall": 0.970856102003643,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9717411121239744,
          "precision": 0.9726277372262774,
          "recall": 0.970856102003643,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.9147609147609148,
        "macro avg": {
          "f1-score": 0.7760356178837994,
          "precision": 0.8346824679592507,
          "recall": 0.751742310614759,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.9104170536549603,
          "precision": 0.9097429590097187,
          "recall": 0.9147609147609148,
          "support": 962
        }
      },
      "test_run_time": "4m4s",
      "total_run_time": "8m3s",
      "train_run_time": "3m59s",
      "type": "nlu"
    },
    "Spacy + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.957388939256573,
          "precision": 0.9530685920577617,
          "recall": 0.9617486338797814,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.957388939256573,
          "precision": 0.9530685920577617,
          "recall": 0.9617486338797814,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9573889392565729,
          "precision": 0.9530685920577618,
          "recall": 0.9617486338797814,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.841995841995842,
        "macro avg": {
          "f1-score": 0.6238813857775629,
          "precision": 0.7168888980373709,
          "recall": 0.5769371339583358,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.8383146362005468,
          "precision": 0.8401861008209651,
          "recall": 0.841995841995842,
          "support": 962
        }
      },
      "test_run_time": "54s",
      "total_run_time": "4m22s",
      "train_run_time": "3m28s",
      "type": "nlu"
    },
    "Spacy + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.9445438282647585,
          "precision": 0.9279437609841827,
          "recall": 0.9617486338797814,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.9445438282647585,
          "precision": 0.9279437609841827,
          "recall": 0.9617486338797814,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9445438282647585,
          "precision": 0.9279437609841827,
          "recall": 0.9617486338797814,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8523908523908524,
        "macro avg": {
          "f1-score": 0.6526677835549815,
          "precision": 0.741625465638199,
          "recall": 0.6190084102005474,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.8476738353673322,
          "precision": 0.8501295840632784,
          "recall": 0.8523908523908524,
          "support": 962
        }
      },
      "test_run_time": "2m49s",
      "total_run_time": "7m47s",
      "train_run_time": "4m58s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.9612263300270515,
          "precision": 0.9517857142857142,
          "recall": 0.970856102003643,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.9612263300270515,
          "precision": 0.9517857142857142,
          "recall": 0.970856102003643,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9612263300270515,
          "precision": 0.9517857142857143,
          "recall": 0.970856102003643,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.896049896049896,
        "macro avg": {
          "f1-score": 0.7502332315326156,
          "precision": 0.778747795414462,
          "recall": 0.7350102948203404,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.8948633780120036,
          "precision": 0.8953707934477166,
          "recall": 0.896049896049896,
          "support": 962
        }
      },
      "test_run_time": "48s",
      "total_run_time": "4m44s",
      "train_run_time": "3m56s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.9679780420860019,
          "precision": 0.9724264705882353,
          "recall": 0.9635701275045537,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.9679780420860019,
          "precision": 0.9724264705882353,
          "recall": 0.9635701275045537,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9679780420860018,
          "precision": 0.9724264705882354,
          "recall": 0.9635701275045537,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.9074844074844075,
        "macro avg": {
          "f1-score": 0.7384698072928593,
          "precision": 0.7676279220877267,
          "recall": 0.7289902382593774,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.9024166165730354,
          "precision": 0.9024817147583407,
          "recall": 0.9074844074844075,
          "support": 962
        }
      },
      "test_run_time": "2m37s",
      "total_run_time": "6m49s",
      "train_run_time": "4m13s",
      "type": "nlu"
    },
    "Sparse + Spacy + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.957388939256573,
          "precision": 0.9530685920577617,
          "recall": 0.9617486338797814,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.957388939256573,
          "precision": 0.9530685920577617,
          "recall": 0.9617486338797814,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9573889392565729,
          "precision": 0.9530685920577618,
          "recall": 0.9617486338797814,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8929313929313929,
        "macro avg": {
          "f1-score": 0.7124353018572713,
          "precision": 0.7508664769596829,
          "recall": 0.6935624939241403,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.888531920235672,
          "precision": 0.8890735676677978,
          "recall": 0.8929313929313929,
          "support": 962
        }
      },
      "test_run_time": "1m3s",
      "total_run_time": "6m14s",
      "train_run_time": "5m12s",
      "type": "nlu"
    },
    "Sparse + Spacy + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.9680365296803652,
          "precision": 0.9706959706959707,
          "recall": 0.9653916211293261,
          "support": 549
        },
        "micro avg": {
          "f1-score": 0.9680365296803652,
          "precision": 0.9706959706959707,
          "recall": 0.9653916211293261,
          "support": 549
        },
        "weighted avg": {
          "f1-score": 0.9680365296803654,
          "precision": 0.9706959706959708,
          "recall": 0.9653916211293261,
          "support": 549
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8898128898128899,
        "macro avg": {
          "f1-score": 0.698640861101418,
          "precision": 0.7515910968310708,
          "recall": 0.6711204898845157,
          "support": 962
        },
        "weighted avg": {
          "f1-score": 0.8795706700463874,
          "precision": 0.8784859335644617,
          "recall": 0.8898128898128899,
          "support": 962
        }
      },
      "test_run_time": "3m11s",
      "total_run_time": "9m18s",
      "train_run_time": "6m8s",
      "type": "nlu"
    }
  },
  "private/service_faq": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.9176954732510288,
        "macro avg": {
          "f1-score": 0.9097074399959015,
          "precision": 0.9288995726495725,
          "recall": 0.9088980463980464,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.9161335349606955,
          "precision": 0.9300868770004571,
          "recall": 0.9176954732510288,
          "support": 243
        }
      },
      "test_run_time": "1m10s",
      "total_run_time": "2m24s",
      "train_run_time": "1m15s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8436213991769548,
        "macro avg": {
          "f1-score": 0.8041509772279002,
          "precision": 0.861881868131868,
          "recall": 0.8085775335775336,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.8333220506060012,
          "precision": 0.8775509127360979,
          "recall": 0.8436213991769548,
          "support": 243
        }
      },
      "test_run_time": "1m23s",
      "total_run_time": "2m19s",
      "train_run_time": "56s",
      "type": "nlu"
    },
    "Spacy + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.6172839506172839,
        "macro avg": {
          "f1-score": 0.5861940410017333,
          "precision": 0.6668167480667481,
          "recall": 0.579235347985348,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.6064297499482684,
          "precision": 0.6624866636183507,
          "recall": 0.6172839506172839,
          "support": 243
        }
      },
      "test_run_time": "44s",
      "total_run_time": "1m45s",
      "train_run_time": "1m2s",
      "type": "nlu"
    },
    "Spacy + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.6255144032921811,
        "macro avg": {
          "f1-score": 0.5656418870219775,
          "precision": 0.6131176622522777,
          "recall": 0.5949256625727214,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.5905498587052691,
          "precision": 0.6255665847641156,
          "recall": 0.6255144032921811,
          "support": 243
        }
      },
      "test_run_time": "55s",
      "total_run_time": "1m45s",
      "train_run_time": "50s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8683127572016461,
        "macro avg": {
          "f1-score": 0.8482054647213015,
          "precision": 0.881013431013431,
          "recall": 0.8539529914529914,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.8655031753797184,
          "precision": 0.8946371415507218,
          "recall": 0.8683127572016461,
          "support": 243
        }
      },
      "test_run_time": "38s",
      "total_run_time": "1m45s",
      "train_run_time": "1m7s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8641975308641975,
        "macro avg": {
          "f1-score": 0.8506632256632256,
          "precision": 0.8879273504273504,
          "recall": 0.851068376068376,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.8602182910824886,
          "precision": 0.8927297668038409,
          "recall": 0.8641975308641975,
          "support": 243
        }
      },
      "test_run_time": "53s",
      "total_run_time": "1m48s",
      "train_run_time": "56s",
      "type": "nlu"
    },
    "Sparse + Spacy + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8477366255144033,
        "macro avg": {
          "f1-score": 0.82684442254578,
          "precision": 0.8671703296703298,
          "recall": 0.8352564102564103,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.842055597647464,
          "precision": 0.8780064014631915,
          "recall": 0.8477366255144033,
          "support": 243
        }
      },
      "test_run_time": "47s",
      "total_run_time": "2m16s",
      "train_run_time": "1m29s",
      "type": "nlu"
    },
    "Sparse + Spacy + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8600823045267489,
        "macro avg": {
          "f1-score": 0.8399240182894027,
          "precision": 0.8894688644688645,
          "recall": 0.8405982905982905,
          "support": 243
        },
        "weighted avg": {
          "f1-score": 0.856515695095942,
          "precision": 0.8937781697040956,
          "recall": 0.8600823045267489,
          "support": 243
        }
      },
      "test_run_time": "54s",
      "total_run_time": "1m55s",
      "train_run_time": "1m1s",
      "type": "nlu"
    }
  },
  "public/HERMIT/KFold_1": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.6157186154866183,
          "precision": 0.745709402347005,
          "recall": 0.549095418493436,
          "support": 1356
        },
        "micro avg": {
          "f1-score": 0.7504201680672269,
          "precision": 0.8720703125,
          "recall": 0.6585545722713865,
          "support": 1356
        },
        "weighted avg": {
          "f1-score": 0.7308828937502307,
          "precision": 0.854302833581822,
          "recall": 0.6585545722713865,
          "support": 1356
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8977695167286245,
        "macro avg": {
          "f1-score": 0.8927282909750941,
          "precision": 0.8942421782266059,
          "recall": 0.8951149031432749,
          "support": 1076
        },
        "weighted avg": {
          "f1-score": 0.8962262725169633,
          "precision": 0.8980930310849722,
          "recall": 0.8977695167286245,
          "support": 1076
        }
      },
      "test_run_time": "3m20s",
      "total_run_time": "25m11s",
      "train_run_time": "21m51s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.6157186154866184,
          "precision": 0.745709402347005,
          "recall": 0.549095418493436,
          "support": 1356
        },
        "micro avg": {
          "f1-score": 0.7504201680672269,
          "precision": 0.8720703125,
          "recall": 0.6585545722713865,
          "support": 1356
        },
        "weighted avg": {
          "f1-score": 0.7308828937502309,
          "precision": 0.854302833581822,
          "recall": 0.6585545722713865,
          "support": 1356
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8689591078066915,
        "macro avg": {
          "f1-score": 0.8698394426835652,
          "precision": 0.8776289316963359,
          "recall": 0.8730256631161237,
          "support": 1076
        },
        "weighted avg": {
          "f1-score": 0.867635705998656,
          "precision": 0.8751246005989126,
          "recall": 0.8689591078066915,
          "support": 1076
        }
      },
      "test_run_time": "3m50s",
      "total_run_time": "33m24s",
      "train_run_time": "29m34s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.6157186154866184,
          "precision": 0.7457094023470052,
          "recall": 0.549095418493436,
          "support": 1356
        },
        "micro avg": {
          "f1-score": 0.7504201680672269,
          "precision": 0.8720703125,
          "recall": 0.6585545722713865,
          "support": 1356
        },
        "weighted avg": {
          "f1-score": 0.7308828937502309,
          "precision": 0.854302833581822,
          "recall": 0.6585545722713865,
          "support": 1356
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.828996282527881,
        "macro avg": {
          "f1-score": 0.8341794923652556,
          "precision": 0.8397039170338345,
          "recall": 0.8396766656223893,
          "support": 1076
        },
        "weighted avg": {
          "f1-score": 0.8280496915480956,
          "precision": 0.8353899142556164,
          "recall": 0.828996282527881,
          "support": 1076
        }
      },
      "test_run_time": "1m26s",
      "total_run_time": "22m55s",
      "train_run_time": "21m30s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.6431575887479123,
          "precision": 0.6951502981851163,
          "recall": 0.6201720297731066,
          "support": 1356
        },
        "micro avg": {
          "f1-score": 0.7601390498261877,
          "precision": 0.7980535279805353,
          "recall": 0.7256637168141593,
          "support": 1356
        },
        "weighted avg": {
          "f1-score": 0.7512243417049524,
          "precision": 0.7973607087337787,
          "recall": 0.7256637168141593,
          "support": 1356
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8382899628252788,
        "macro avg": {
          "f1-score": 0.8343972263954396,
          "precision": 0.8392347622271736,
          "recall": 0.8428581218671679,
          "support": 1076
        },
        "weighted avg": {
          "f1-score": 0.8352572190136305,
          "precision": 0.8437043678076097,
          "recall": 0.8382899628252788,
          "support": 1076
        }
      },
      "test_run_time": "3m7s",
      "total_run_time": "20m52s",
      "train_run_time": "17m45s",
      "type": "nlu"
    }
  },
  "public/Sara": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.5317217358770205,
          "precision": 0.5747159838345217,
          "recall": 0.5102144459666825,
          "support": 440
        },
        "micro avg": {
          "f1-score": 0.7949308755760369,
          "precision": 0.8060747663551402,
          "recall": 0.7840909090909091,
          "support": 440
        },
        "weighted avg": {
          "f1-score": 0.7678349293582227,
          "precision": 0.771290573938493,
          "recall": 0.7840909090909091,
          "support": 440
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.7703974195647512,
          "precision": 0.8010311264874886,
          "recall": 0.7792264325876231,
          "support": 2077
        },
        "micro avg": {
          "f1-score": 0.7174174897615032,
          "precision": 0.7179363548698168,
          "recall": 0.7168993740972557,
          "support": 2077
        },
        "weighted avg": {
          "f1-score": 0.7046090683695049,
          "precision": 0.7304683000064325,
          "recall": 0.7168993740972557,
          "support": 2077
        }
      },
      "response_selection": {
        "accuracy": 0.7968992248062016,
        "macro avg": {
          "f1-score": 0.7301810597800666,
          "precision": 0.6852374302894385,
          "recall": 0.794134078874094,
          "support": 645
        },
        "weighted avg": {
          "f1-score": 0.77274618341544,
          "precision": 0.7626528484284721,
          "recall": 0.7968992248062016,
          "support": 645
        }
      },
      "test_run_time": "6m8s",
      "total_run_time": "13m10s",
      "train_run_time": "7m3s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.5531316134696741,
          "precision": 0.5565390749601276,
          "recall": 0.5883597163990275,
          "support": 440
        },
        "micro avg": {
          "f1-score": 0.7924528301886793,
          "precision": 0.7744034707158352,
          "recall": 0.8113636363636364,
          "support": 440
        },
        "weighted avg": {
          "f1-score": 0.7693029190764111,
          "precision": 0.7489151274363596,
          "recall": 0.8113636363636364,
          "support": 440
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.7902778022725805,
          "precision": 0.8176378688451061,
          "recall": 0.8079873113685737,
          "support": 2077
        },
        "micro avg": {
          "f1-score": 0.7135629968682247,
          "precision": 0.7140790742526519,
          "recall": 0.7130476649013,
          "support": 2077
        },
        "weighted avg": {
          "f1-score": 0.6951996467257159,
          "precision": 0.7263859203900425,
          "recall": 0.7130476649013,
          "support": 2077
        }
      },
      "response_selection": {
        "accuracy": 0.7798449612403101,
        "macro avg": {
          "f1-score": 0.7210733775328546,
          "precision": 0.6859198076668838,
          "recall": 0.7843376538063411,
          "support": 645
        },
        "weighted avg": {
          "f1-score": 0.7572211831483341,
          "precision": 0.7502423012184335,
          "recall": 0.7798449612403101,
          "support": 645
        }
      },
      "test_run_time": "8m25s",
      "total_run_time": "14m17s",
      "train_run_time": "5m52s",
      "type": "nlu"
    },
    "Rules": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "story_prediction": {
        "accuracy": 0.12664802237315223,
        "conversation_accuracy": {
          "accuracy": 0.0,
          "correct": 0,
          "total": 292,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.19891830560426044,
          "precision": 0.3102682617210462,
          "recall": 0.1956210192055683,
          "support": 5006
        },
        "weighted avg": {
          "f1-score": 0.17849263458894135,
          "precision": 0.6082029295657687,
          "recall": 0.12664802237315223,
          "support": 5006
        }
      },
      "test_run_time": "1m26s",
      "total_run_time": "4m3s",
      "train_run_time": "2m37s",
      "type": "core"
    },
    "Rules + AugMemo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.6643835616438356,
          "correct": 194,
          "total": 292,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.8496937351476788,
          "precision": 0.8964763343535831,
          "recall": 0.8217131868065152,
          "support": 5006
        },
        "micro avg": {
          "f1-score": 0.9214785214785215,
          "precision": 0.9216626698641087,
          "recall": 0.9212944466640032,
          "support": 5006
        },
        "weighted avg": {
          "f1-score": 0.950664304339034,
          "precision": 0.9875664791183741,
          "recall": 0.9212944466640032,
          "support": 5006
        }
      },
      "test_run_time": "1m42s",
      "total_run_time": "4m21s",
      "train_run_time": "2m40s",
      "type": "core"
    },
    "Rules + AugMemo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.7465753424657534,
          "correct": 218,
          "total": 292,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.9050737197622357,
          "precision": 0.9163723858756511,
          "recall": 0.9002918167972438,
          "support": 5006
        },
        "micro avg": {
          "f1-score": 0.9706293706293706,
          "precision": 0.9708233413269385,
          "recall": 0.9704354774270875,
          "support": 5006
        },
        "weighted avg": {
          "f1-score": 0.9749178520641076,
          "precision": 0.9810656196859578,
          "recall": 0.9704354774270875,
          "support": 5006
        }
      },
      "test_run_time": "7m30s",
      "total_run_time": "53m26s",
      "train_run_time": "45m57s",
      "type": "core"
    },
    "Rules + Memo": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.14383561643835616,
          "correct": 42,
          "total": 292,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.29960897896413713,
          "precision": 0.5336074034988815,
          "recall": 0.2664437643372244,
          "support": 5006
        },
        "micro avg": {
          "f1-score": 0.3859754270302667,
          "precision": 0.386013986013986,
          "recall": 0.38593687574910107,
          "support": 5006
        },
        "weighted avg": {
          "f1-score": 0.5029446038870674,
          "precision": 0.9206814386648188,
          "recall": 0.38593687574910107,
          "support": 5006
        }
      },
      "test_run_time": "1m32s",
      "total_run_time": "4m10s",
      "train_run_time": "2m38s",
      "type": "core"
    },
    "Rules + Memo + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.6232876712328768,
          "correct": 182,
          "total": 292,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.8874356548857827,
          "precision": 0.9152689991228523,
          "recall": 0.880879984214624,
          "support": 5006
        },
        "micro avg": {
          "f1-score": 0.9443389627260917,
          "precision": 0.9448110377924415,
          "recall": 0.9438673591689972,
          "support": 5006
        },
        "weighted avg": {
          "f1-score": 0.9558193025189263,
          "precision": 0.9746621151171727,
          "recall": 0.9438673591689972,
          "support": 5006
        }
      },
      "test_run_time": "7m49s",
      "total_run_time": "57m4s",
      "train_run_time": "49m15s",
      "type": "core"
    },
    "Rules + TED": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "external_dataset_repository": false,
      "story_prediction": {
        "conversation_accuracy": {
          "accuracy": 0.6232876712328768,
          "correct": 182,
          "total": 292,
          "with_warnings": 0
        },
        "macro avg": {
          "f1-score": 0.871982092826866,
          "precision": 0.9012019823885822,
          "recall": 0.8653063598388325,
          "support": 5006
        },
        "micro avg": {
          "f1-score": 0.9452438049560352,
          "precision": 0.9456217512994802,
          "recall": 0.9448661606072712,
          "support": 5006
        },
        "weighted avg": {
          "f1-score": 0.9559006382884447,
          "precision": 0.9741360484050476,
          "recall": 0.9448661606072712,
          "support": 5006
        }
      },
      "test_run_time": "7m18s",
      "total_run_time": "53m55s",
      "train_run_time": "46m37s",
      "type": "core"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.5317217358770205,
          "precision": 0.5747159838345216,
          "recall": 0.5102144459666825,
          "support": 440
        },
        "micro avg": {
          "f1-score": 0.7949308755760369,
          "precision": 0.8060747663551402,
          "recall": 0.7840909090909091,
          "support": 440
        },
        "weighted avg": {
          "f1-score": 0.7678349293582227,
          "precision": 0.771290573938493,
          "recall": 0.7840909090909091,
          "support": 440
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.7841785381470693,
          "precision": 0.7972996788795962,
          "recall": 0.8065657436995322,
          "support": 2077
        },
        "micro avg": {
          "f1-score": 0.6966995904601301,
          "precision": 0.6972034715525555,
          "recall": 0.6961964371689937,
          "support": 2077
        },
        "weighted avg": {
          "f1-score": 0.6787460987231257,
          "precision": 0.7092896883884404,
          "recall": 0.6961964371689937,
          "support": 2077
        }
      },
      "response_selection": {
        "accuracy": 0.8031007751937984,
        "macro avg": {
          "f1-score": 0.7324022592502945,
          "precision": 0.7092643446015043,
          "recall": 0.7810154612359161,
          "support": 645
        },
        "weighted avg": {
          "f1-score": 0.7801029832204501,
          "precision": 0.7801274007195325,
          "recall": 0.8031007751937984,
          "support": 645
        }
      },
      "test_run_time": "7m25s",
      "total_run_time": "18m53s",
      "train_run_time": "11m29s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.5528474025669261,
          "precision": 0.5478139738611573,
          "recall": 0.5940476320992703,
          "support": 440
        },
        "micro avg": {
          "f1-score": 0.789071038251366,
          "precision": 0.76,
          "recall": 0.8204545454545454,
          "support": 440
        },
        "weighted avg": {
          "f1-score": 0.766672611319055,
          "precision": 0.7337221018575244,
          "recall": 0.8204545454545454,
          "support": 440
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.7686783912900307,
          "precision": 0.7626800394378628,
          "recall": 0.8173042996835812,
          "support": 2077
        },
        "micro avg": {
          "f1-score": 0.7039267646350277,
          "precision": 0.7044358727097396,
          "recall": 0.7034183919114106,
          "support": 2077
        },
        "weighted avg": {
          "f1-score": 0.6786927568657116,
          "precision": 0.7178540305115553,
          "recall": 0.7034183919114106,
          "support": 2077
        }
      },
      "response_selection": {
        "accuracy": 0.7844961240310078,
        "macro avg": {
          "f1-score": 0.7375579986473847,
          "precision": 0.7025594544105896,
          "recall": 0.797415628635529,
          "support": 645
        },
        "weighted avg": {
          "f1-score": 0.7598078151909952,
          "precision": 0.7637955997717321,
          "recall": 0.7844961240310078,
          "support": 645
        }
      },
      "test_run_time": "10m10s",
      "total_run_time": "19m10s",
      "train_run_time": "9m0s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.5317217358770205,
          "precision": 0.5747159838345216,
          "recall": 0.5102144459666825,
          "support": 440
        },
        "micro avg": {
          "f1-score": 0.7949308755760369,
          "precision": 0.8060747663551402,
          "recall": 0.7840909090909091,
          "support": 440
        },
        "weighted avg": {
          "f1-score": 0.7678349293582227,
          "precision": 0.771290573938493,
          "recall": 0.7840909090909091,
          "support": 440
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.7588870940172708,
          "precision": 0.7533451229564776,
          "recall": 0.8035155939461912,
          "support": 2077
        },
        "micro avg": {
          "f1-score": 0.6706817634304987,
          "precision": 0.6711668273866924,
          "recall": 0.6701974000962927,
          "support": 2077
        },
        "weighted avg": {
          "f1-score": 0.6419022989078554,
          "precision": 0.6884323613918314,
          "recall": 0.6701974000962927,
          "support": 2077
        }
      },
      "response_selection": {
        "accuracy": 0.7906976744186046,
        "macro avg": {
          "f1-score": 0.736159818823764,
          "precision": 0.720360975951565,
          "recall": 0.7726162916285895,
          "support": 645
        },
        "weighted avg": {
          "f1-score": 0.7642127089829898,
          "precision": 0.7578686694972505,
          "recall": 0.7906976744186046,
          "support": 645
        }
      },
      "test_run_time": "2m49s",
      "total_run_time": "11m0s",
      "train_run_time": "8m11s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.5347942281194251,
          "precision": 0.5024156609664149,
          "recall": 0.6094219122044091,
          "support": 440
        },
        "micro avg": {
          "f1-score": 0.7683982683982684,
          "precision": 0.7334710743801653,
          "recall": 0.8068181818181818,
          "support": 440
        },
        "weighted avg": {
          "f1-score": 0.7461589239314861,
          "precision": 0.7089792706396797,
          "recall": 0.8068181818181818,
          "support": 440
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "macro avg": {
          "f1-score": 0.7466069037837121,
          "precision": 0.7512029340057192,
          "recall": 0.7926133278502662,
          "support": 2077
        },
        "micro avg": {
          "f1-score": 0.6783907492170561,
          "precision": 0.6788813886210222,
          "recall": 0.6779008184882042,
          "support": 2077
        },
        "weighted avg": {
          "f1-score": 0.6543726701356195,
          "precision": 0.7005896672303581,
          "recall": 0.6779008184882042,
          "support": 2077
        }
      },
      "response_selection": {
        "accuracy": 0.7891472868217054,
        "macro avg": {
          "f1-score": 0.7386236631526188,
          "precision": 0.7218505544028552,
          "recall": 0.7730150660279185,
          "support": 645
        },
        "weighted avg": {
          "f1-score": 0.763546556002089,
          "precision": 0.7604900104080233,
          "recall": 0.7891472868217054,
          "support": 645
        }
      },
      "test_run_time": "5m51s",
      "total_run_time": "12m32s",
      "train_run_time": "6m41s",
      "type": "nlu"
    }
  },
  "public/carbon-bot": {
    "BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7112627814240716,
          "precision": 0.7568913536233798,
          "recall": 0.700853910733117,
          "support": 186
        },
        "micro avg": {
          "f1-score": 0.7529411764705883,
          "precision": 0.8311688311688312,
          "recall": 0.6881720430107527,
          "support": 186
        },
        "weighted avg": {
          "f1-score": 0.7508096236634219,
          "precision": 0.8362424583170947,
          "recall": 0.6881720430107527,
          "support": 186
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7941747572815534,
        "macro avg": {
          "f1-score": 0.6977281041026943,
          "precision": 0.7497205320692165,
          "recall": 0.6840454982554302,
          "support": 515
        },
        "weighted avg": {
          "f1-score": 0.7891729510619914,
          "precision": 0.797211860675332,
          "recall": 0.7941747572815534,
          "support": 515
        }
      },
      "response_selection": {
        "macro avg": {
          "f1-score": 0.5325227317846333,
          "precision": 0.5753244697689142,
          "recall": 0.5491045991045992,
          "support": 151
        },
        "micro avg": {
          "f1-score": 0.5382059800664453,
          "precision": 0.54,
          "recall": 0.5364238410596026,
          "support": 151
        },
        "weighted avg": {
          "f1-score": 0.5308657787920191,
          "precision": 0.5753738902745525,
          "recall": 0.5364238410596026,
          "support": 151
        }
      },
      "test_run_time": "2m1s",
      "total_run_time": "7m31s",
      "train_run_time": "5m31s",
      "type": "nlu"
    },
    "BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7297610631399961,
          "precision": 0.7207571977417013,
          "recall": 0.7613723516441376,
          "support": 186
        },
        "micro avg": {
          "f1-score": 0.7786666666666667,
          "precision": 0.7724867724867724,
          "recall": 0.7849462365591398,
          "support": 186
        },
        "weighted avg": {
          "f1-score": 0.7739322458884702,
          "precision": 0.7706736469590726,
          "recall": 0.7849462365591398,
          "support": 186
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.8077669902912621,
        "macro avg": {
          "f1-score": 0.7031772150278984,
          "precision": 0.7702659608909609,
          "recall": 0.6877793696553515,
          "support": 515
        },
        "weighted avg": {
          "f1-score": 0.8008935450163739,
          "precision": 0.810205754331968,
          "recall": 0.8077669902912621,
          "support": 515
        }
      },
      "response_selection": {
        "accuracy": 0.5298013245033113,
        "macro avg": {
          "f1-score": 0.5032940277422612,
          "precision": 0.5528301944968611,
          "recall": 0.5210453127119794,
          "support": 151
        },
        "weighted avg": {
          "f1-score": 0.5213553036345672,
          "precision": 0.574778992163098,
          "recall": 0.5298013245033113,
          "support": 151
        }
      },
      "test_run_time": "3m19s",
      "total_run_time": "8m11s",
      "train_run_time": "4m52s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7112627814240717,
          "precision": 0.7568913536233798,
          "recall": 0.700853910733117,
          "support": 186
        },
        "micro avg": {
          "f1-score": 0.7529411764705883,
          "precision": 0.8311688311688312,
          "recall": 0.6881720430107527,
          "support": 186
        },
        "weighted avg": {
          "f1-score": 0.7508096236634217,
          "precision": 0.8362424583170945,
          "recall": 0.6881720430107527,
          "support": 186
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7902912621359224,
        "macro avg": {
          "f1-score": 0.729094241577879,
          "precision": 0.7763425094838406,
          "recall": 0.714997587168849,
          "support": 515
        },
        "weighted avg": {
          "f1-score": 0.7867325163198896,
          "precision": 0.7932232094721219,
          "recall": 0.7902912621359224,
          "support": 515
        }
      },
      "response_selection": {
        "accuracy": 0.5695364238410596,
        "macro avg": {
          "f1-score": 0.5354645904242081,
          "precision": 0.5795627212293879,
          "recall": 0.5681183014516348,
          "support": 151
        },
        "weighted avg": {
          "f1-score": 0.5495226419926338,
          "precision": 0.5917062518055896,
          "recall": 0.5695364238410596,
          "support": 151
        }
      },
      "test_run_time": "2m12s",
      "total_run_time": "7m29s",
      "train_run_time": "5m16s",
      "type": "nlu"
    },
    "Sparse + BERT + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7284648658683746,
          "precision": 0.7372442908594868,
          "recall": 0.7440031088650589,
          "support": 186
        },
        "micro avg": {
          "f1-score": 0.7880434782608695,
          "precision": 0.7967032967032966,
          "recall": 0.7795698924731183,
          "support": 186
        },
        "weighted avg": {
          "f1-score": 0.7850557037755679,
          "precision": 0.7955656528207524,
          "recall": 0.7795698924731183,
          "support": 186
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7805825242718447,
        "macro avg": {
          "f1-score": 0.6978508579968884,
          "precision": 0.7168286710566122,
          "recall": 0.7119952012382459,
          "support": 515
        },
        "weighted avg": {
          "f1-score": 0.7804641544319427,
          "precision": 0.7901557418404934,
          "recall": 0.7805825242718447,
          "support": 515
        }
      },
      "response_selection": {
        "accuracy": 0.5629139072847682,
        "macro avg": {
          "f1-score": 0.5141126630634715,
          "precision": 0.5494829244829245,
          "recall": 0.5382241215574549,
          "support": 151
        },
        "weighted avg": {
          "f1-score": 0.5476754226257025,
          "precision": 0.5829828559961009,
          "recall": 0.5629139072847682,
          "support": 151
        }
      },
      "test_run_time": "3m39s",
      "total_run_time": "9m25s",
      "train_run_time": "5m47s",
      "type": "nlu"
    },
    "Sparse + DIET(bow) + ResponseSelector(bow)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.7112627814240717,
          "precision": 0.7568913536233798,
          "recall": 0.700853910733117,
          "support": 186
        },
        "micro avg": {
          "f1-score": 0.7529411764705883,
          "precision": 0.8311688311688312,
          "recall": 0.6881720430107527,
          "support": 186
        },
        "weighted avg": {
          "f1-score": 0.7508096236634219,
          "precision": 0.8362424583170945,
          "recall": 0.6881720430107527,
          "support": 186
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7436893203883496,
        "macro avg": {
          "f1-score": 0.6494236854923695,
          "precision": 0.7096346158048235,
          "recall": 0.6365875944431384,
          "support": 515
        },
        "weighted avg": {
          "f1-score": 0.7412298408328885,
          "precision": 0.75660417091526,
          "recall": 0.7436893203883496,
          "support": 515
        }
      },
      "response_selection": {
        "macro avg": {
          "f1-score": 0.5131698972958082,
          "precision": 0.5554232804232805,
          "recall": 0.5279439696106363,
          "support": 151
        },
        "micro avg": {
          "f1-score": 0.5581395348837209,
          "precision": 0.56,
          "recall": 0.5562913907284768,
          "support": 151
        },
        "weighted avg": {
          "f1-score": 0.5181173379768278,
          "precision": 0.5472222222222222,
          "recall": 0.5562913907284768,
          "support": 151
        }
      },
      "test_run_time": "58s",
      "total_run_time": "3m57s",
      "train_run_time": "3m0s",
      "type": "nlu"
    },
    "Sparse + DIET(seq) + ResponseSelector(t2t)": {
      "accelerator_type": "GPU",
      "config_repository": "training-data",
      "config_repository_branch": "main",
      "dataset_commit": "819cb7b3cc077753e67178ad022d577f164e99cf",
      "dataset_repository_branch": "main",
      "entity_prediction": {
        "macro avg": {
          "f1-score": 0.6380499493244591,
          "precision": 0.6319284122689696,
          "recall": 0.6805500773792406,
          "support": 186
        },
        "micro avg": {
          "f1-score": 0.702247191011236,
          "precision": 0.7352941176470589,
          "recall": 0.6720430107526881,
          "support": 186
        },
        "weighted avg": {
          "f1-score": 0.6991853330800202,
          "precision": 0.7390018630006645,
          "recall": 0.6720430107526881,
          "support": 186
        }
      },
      "external_dataset_repository": false,
      "intent_classification": {
        "accuracy": 0.7398058252427184,
        "macro avg": {
          "f1-score": 0.6165585856283674,
          "precision": 0.6351060491246306,
          "recall": 0.6304971099631302,
          "support": 515
        },
        "weighted avg": {
          "f1-score": 0.7386309453909478,
          "precision": 0.7497560497857724,
          "recall": 0.7398058252427184,
          "support": 515
        }
      },
      "response_selection": {
        "accuracy": 0.5298013245033113,
        "macro avg": {
          "f1-score": 0.47350026118557914,
          "precision": 0.5184009406231629,
          "recall": 0.513658255324922,
          "support": 151
        },
        "weighted avg": {
          "f1-score": 0.4900268264383155,
          "precision": 0.529617365710081,
          "recall": 0.5298013245033113,
          "support": 151
        }
      },
      "test_run_time": "2m52s",
      "total_run_time": "7m56s",
      "train_run_time": "5m4s",
      "type": "nlu"
    }
  }
}